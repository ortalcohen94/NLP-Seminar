{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e6ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters:\n",
    "\n",
    "SHOULD_USE_SEED = True\n",
    "RADIUS = 10000\n",
    "BATCH_SIZE = 700\n",
    "EPSILON = 0.1\n",
    "SIGMA = 0.0001\n",
    "MAX_ITERS = 100\n",
    "\n",
    "TRAIN_FILE = \"snli_1.0_train.txt\"\n",
    "VAL_FILE = \"snli_1.0_dev.txt\"\n",
    "TEST_FILE = \"snli_1.0_test.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfac5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from data.data_creator import data_create_SNLI\n",
    "\n",
    "if SHOULD_USE_SEED:\n",
    "    np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e290f6b",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3919a68e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, labels = data_create_SNLI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4337536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset by using the original split\n",
    "\n",
    "x_train, x_val, x_test = data[TRAIN_FILE], data[VAL_FILE], data[TEST_FILE]\n",
    "y_train, y_val, y_test = labels[TRAIN_FILE], labels[VAL_FILE], labels[TEST_FILE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c07f7",
   "metadata": {},
   "source": [
    "## Black-box model - Multinomial Naive Bayes classifier\n",
    "\n",
    "The black box model that was used in the original article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c84857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data_multinomial_nb = dict()\n",
    "\n",
    "for key in data:\n",
    "    data_multinomial_nb[key] = \\\n",
    "        [first + ', ' + second for first, second in zip(data[key]['premise'], data[key]['hypothesis'])]\n",
    "    \n",
    "x_train, x_val, x_test = data_multinomial_nb[TRAIN_FILE], data_multinomial_nb[VAL_FILE], data_multinomial_nb[TEST_FILE]\n",
    "\n",
    "vect_text = TfidfVectorizer(use_idf = False)\n",
    "x_vec_train = vect_text.fit_transform(x_train)\n",
    "\n",
    "clf = MultinomialNB().fit(x_vec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8a419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(vect_text.transform(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52677dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.5363\n"
     ]
    }
   ],
   "source": [
    "print('Val accuracy', metrics.accuracy_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb75a5",
   "metadata": {},
   "source": [
    "## Black-box model - Multinomial Naive Bayes classifier\n",
    "\n",
    "The black box model above doesn't give a good result. Therefore, we use another black box model presented in the following article:\n",
    "https://nlp.stanford.edu/pubs/snli_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba8c0a",
   "metadata": {},
   "source": [
    "### Data preperation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13b45fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field\n",
    "\n",
    "x_train, x_val, x_test = data[TRAIN_FILE], data[VAL_FILE], data[TEST_FILE] \n",
    "\n",
    "text_field = Field(\n",
    "    tokenize='basic_english', \n",
    "    lower=True\n",
    ")\n",
    "label_field = Field(sequential=False, use_vocab=False)\n",
    "# sadly have to apply preprocess manually\n",
    "\n",
    "preprocessed_text = [text_field.preprocess(x) for x in x_train['hypothesis']]#.apply(lambda x: text_field.preprocess(x))\n",
    "# load fastext simple embedding with 300d\n",
    "text_field.build_vocab(\n",
    "     preprocessed_text\n",
    ")\n",
    "vocab = text_field.vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e220f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane.\n"
     ]
    }
   ],
   "source": [
    "print(x_train['premise'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1c585",
   "metadata": {},
   "source": [
    "## Instance to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_explain = x_test[1]#\"the movie's thesis -- elegant technology for the masses -- is surprisingly refreshing .\"\n",
    "print('x to explain: ',x_explain)\n",
    "print('Predicted class: ', clf.predict(vect_text.transform([x_explain]))[0])\n",
    "print('True class: ', y_test[1])\n",
    "print('Predict probablilities: ', clf.predict_proba(vect_text.transform([x_explain]))[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214e6c8",
   "metadata": {},
   "source": [
    "## Building MeLime model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be40a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from torch.utils.data import DataLoader\n",
    "def tokenizer(x):\n",
    "    return x.split()\n",
    "dl_train = [tokenizer(x) for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_models.word2vec_gen import Word2VecGen, Word2VecEncoder\n",
    "#The radius is <radius> most similar words\n",
    "generator = Word2VecGen(encoder = Word2VecEncoder(dl_train), corpus = x_train, radius = RADIUS, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpretable_local_models.statistics_model import StatisticsLocalModel\n",
    "tokenized_x_explain = x_explain.split()\n",
    "y_p_explain = max(clf.predict_proba(vect_text.transform([x_explain]))[0])\n",
    "explainer_model = StatisticsLocalModel(y_p_explain, len(tokenized_x_explain), tokenizer)\n",
    "print(tokenized_x_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a880e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeLime.model import MeLimeModel\n",
    "\n",
    "def transform_func(x):\n",
    "    return vect_text.transform([x])\n",
    "\n",
    "model = MeLimeModel(black_box_model = clf,gen_model =generator, batch_size = BATCH_SIZE, epsilon_c = EPSILON, \n",
    "                    sigma = SIGMA, explainer_model = explainer_model, transform_func = transform_func, \n",
    "                    max_iters = MAX_ITERS, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b988a94",
   "metadata": {},
   "source": [
    "## Explaining the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c56f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, sentences_with_probs = model.forward(x_explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba51b8",
   "metadata": {},
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c15fce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = StatisticsLocalModel.plot_explaination(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "StatisticsLocalModel.plot_sentence_heatmap(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698add19",
   "metadata": {},
   "source": [
    "## Plotting most favorable and contrary samples phrases:\n",
    "\n",
    "Favorable sentence - a generated sentence using Word2VecGen that improves the model's confidence in its \n",
    "prediction on the original sentence.\n",
    "\n",
    "Contrary samples - a generated sentence using Word2VecGen that decrease the model's confidence in its prediction on the original sentence and <b>might even change its prediction on the generated sentence</b>.\n",
    "\n",
    "### Most contrary samples phrases:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sentences_with_probs, key = lambda x: x[1])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f946d2",
   "metadata": {},
   "source": [
    "### Most favorable samples phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd709af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sentences_with_probs, key = lambda x: x[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9eb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
