{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters:\n",
    "\n",
    "SHOULD_USE_SEED = True\n",
    "RADIUS = 10000\n",
    "BATCH_SIZE = 700\n",
    "EPSILON = 0.1\n",
    "SIGMA = 0.0001\n",
    "MAX_ITERS = 100\n",
    "\n",
    "TRAIN_FILE = \"snli_1.0_train.txt\"\n",
    "VAL_FILE = \"snli_1.0_dev.txt\"\n",
    "TEST_FILE = \"snli_1.0_test.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from data.data_creator import data_create_SNLI\n",
    "\n",
    "if SHOULD_USE_SEED:\n",
    "    np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example a premise and hypothesis from the database  A person on a horse jumps over a broken down airplane., A person is training his horse for a competition.\n",
      "Number of instances in the training database:  550152\n"
     ]
    }
   ],
   "source": [
    "data, labels = data_create_SNLI()\n",
    "\n",
    "print(\"Example a premise and hypothesis from the database \", data[TRAIN_FILE][0])\n",
    "print(\"Number of instances in the training database: \", len(data[TRAIN_FILE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset by using the original split\n",
    "\n",
    "x_train, x_val, x_test = data[TRAIN_FILE], data[VAL_FILE], data[TEST_FILE]\n",
    "y_train, y_val, y_test = labels[TRAIN_FILE], labels[VAL_FILE], labels[TEST_FILE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black-box model - Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21069)\t0.4588314677411235\n",
      "  (0, 19756)\t0.22941573387056174\n",
      "  (0, 14131)\t0.4588314677411235\n",
      "  (0, 15708)\t0.22941573387056174\n",
      "  (0, 20121)\t0.22941573387056174\n",
      "  (0, 3965)\t0.22941573387056174\n",
      "  (0, 8979)\t0.22941573387056174\n",
      "  (0, 919)\t0.22941573387056174\n",
      "  (0, 15271)\t0.22941573387056174\n",
      "  (0, 30230)\t0.22941573387056174\n",
      "  (0, 13865)\t0.22941573387056174\n",
      "  (0, 11437)\t0.22941573387056174\n",
      "  (0, 6345)\t0.22941573387056174\n",
      "  (1, 21069)\t0.48507125007266594\n",
      "  (1, 19756)\t0.24253562503633297\n",
      "  (1, 14131)\t0.24253562503633297\n",
      "  (1, 15708)\t0.24253562503633297\n",
      "  (1, 20121)\t0.24253562503633297\n",
      "  (1, 3965)\t0.24253562503633297\n",
      "  (1, 8979)\t0.24253562503633297\n",
      "  (1, 919)\t0.24253562503633297\n",
      "  (1, 15271)\t0.24253562503633297\n",
      "  (1, 1872)\t0.24253562503633297\n",
      "  (1, 8426)\t0.24253562503633297\n",
      "  (1, 19893)\t0.24253562503633297\n",
      "  :\t:\n",
      "  (550150, 15271)\t0.3779644730092272\n",
      "  (550150, 14698)\t0.5669467095138409\n",
      "  (550150, 17390)\t0.3779644730092272\n",
      "  (550150, 29890)\t0.1889822365046136\n",
      "  (550150, 32105)\t0.1889822365046136\n",
      "  (550150, 3412)\t0.1889822365046136\n",
      "  (550150, 3371)\t0.1889822365046136\n",
      "  (550150, 4316)\t0.1889822365046136\n",
      "  (550150, 28512)\t0.1889822365046136\n",
      "  (550150, 2755)\t0.1889822365046136\n",
      "  (550150, 17857)\t0.1889822365046136\n",
      "  (550150, 28681)\t0.1889822365046136\n",
      "  (550150, 13533)\t0.1889822365046136\n",
      "  (550150, 3474)\t0.1889822365046136\n",
      "  (550151, 19756)\t0.15811388300841897\n",
      "  (550151, 15271)\t0.31622776601683794\n",
      "  (550151, 29575)\t0.15811388300841897\n",
      "  (550151, 29528)\t0.15811388300841897\n",
      "  (550151, 14698)\t0.4743416490252569\n",
      "  (550151, 17390)\t0.31622776601683794\n",
      "  (550151, 32105)\t0.31622776601683794\n",
      "  (550151, 3371)\t0.31622776601683794\n",
      "  (550151, 2755)\t0.31622776601683794\n",
      "  (550151, 28681)\t0.31622776601683794\n",
      "  (550151, 3474)\t0.31622776601683794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect_text = TfidfVectorizer(use_idf = False)\n",
    "x_vec_train = vect_text.fit_transform(x_train)\n",
    "\n",
    "clf = MultinomialNB().fit(x_vec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(vect_text.transform(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Val accuracy', metrics.accuracy_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_explain = x_test[1]#\"the movie's thesis -- elegant technology for the masses -- is surprisingly refreshing .\"\n",
    "print('x to explain: ',x_explain)\n",
    "print('Predicted class: ', clf.predict(vect_text.transform([x_explain]))[0])\n",
    "print('True class: ', y_test[1])\n",
    "print('Predict probablilities: ', clf.predict_proba(vect_text.transform([x_explain]))[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building MeLime model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from torch.utils.data import DataLoader\n",
    "def tokenizer(x):\n",
    "    return x.split()\n",
    "dl_train = [tokenizer(x) for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_models.word2vec_gen import Word2VecGen, Word2VecEncoder\n",
    "#The radius is <radius> most similar words\n",
    "generator = Word2VecGen(encoder = Word2VecEncoder(dl_train), corpus = x_train, radius = RADIUS, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpretable_local_models.statistics_model import StatisticsLocalModel\n",
    "tokenized_x_explain = x_explain.split()\n",
    "y_p_explain = max(clf.predict_proba(vect_text.transform([x_explain]))[0])\n",
    "explainer_model = StatisticsLocalModel(y_p_explain, len(tokenized_x_explain), tokenizer)\n",
    "print(tokenized_x_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeLime.model import MeLimeModel\n",
    "\n",
    "def transform_func(x):\n",
    "    return vect_text.transform([x])\n",
    "\n",
    "model = MeLimeModel(black_box_model = clf,gen_model =generator, batch_size = BATCH_SIZE, epsilon_c = EPSILON, \n",
    "                    sigma = SIGMA, explainer_model = explainer_model, transform_func = transform_func, \n",
    "                    max_iters = MAX_ITERS, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, sentences_with_probs = model.forward(x_explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = StatisticsLocalModel.plot_explaination(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "StatisticsLocalModel.plot_sentence_heatmap(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting most favorable and contrary samples phrases:\n",
    "\n",
    "Favorable sentence - a generated sentence using Word2VecGen that improves the model's confidence in its \n",
    "prediction on the original sentence.\n",
    "\n",
    "Contrary samples - a generated sentence using Word2VecGen that decrease the model's confidence in its prediction on the original sentence and <b>might even change its prediction on the generated sentence</b>.\n",
    "\n",
    "### Most contrary samples phrases:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sentences_with_probs, key = lambda x: x[1])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most favorable samples phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sentences_with_probs, key = lambda x: x[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
